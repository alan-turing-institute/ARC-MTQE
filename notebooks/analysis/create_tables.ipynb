{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A notebook that puts evaluation results into a latex table format and prints the result.\n",
    "The results are grouped by result type, e.g., median, max etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from mtqe.utils.paths import EVAL_DIR\n",
    "from mtqe.utils.tables import create_latex_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the data split to be evaluated, and the metrics to be shown in the table\n",
    "DATA_SPLIT = 'test'\n",
    "VALUES = ['precision', 'recall']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "folders = os.listdir(EVAL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "li_max_results = []\n",
    "li_min_results = []\n",
    "li_med_results = []\n",
    "li_mean_results = []\n",
    "li_ensemble_results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect results for all experiment groups\n",
    "for folder in folders:\n",
    "    path = os.path.join(EVAL_DIR, folder)\n",
    "    if os.path.isdir(path):\n",
    "        files = os.listdir(path)\n",
    "        for file in files:\n",
    "            df = pd.read_csv(os.path.join(EVAL_DIR, folder, file))\n",
    "            if file.endswith('ensemble_results.csv'):\n",
    "                li_ensemble_results.append(df)\n",
    "            elif file.endswith('max_results.csv'):\n",
    "                li_max_results.append(df)\n",
    "            elif file.endswith('min_results.csv'):\n",
    "                li_min_results.append(df)\n",
    "            elif file.endswith('median_results.csv'):\n",
    "                li_med_results.append(df)\n",
    "            elif file.endswith('mean_results.csv'):\n",
    "                li_mean_results.append(df)\n",
    "\n",
    "df_ensemble = pd.concat(li_ensemble_results)\n",
    "df_max = pd.concat(li_max_results)\n",
    "df_min = pd.concat(li_min_results)\n",
    "df_med = pd.concat(li_med_results)\n",
    "df_mean = pd.concat(li_mean_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_exp_group_names(row):\n",
    "    if row['exp_group'][-4:] == 'enja':\n",
    "        row['exp_group'] = row['exp_group'][:-5]\n",
    "    return row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Move en-ja results to same group as other language pairs, if they are separate.\n",
    "df_max = df_max.apply(update_exp_group_names, axis=1)\n",
    "df_min = df_min.apply(update_exp_group_names, axis=1)\n",
    "df_med = df_med.apply(update_exp_group_names, axis=1)\n",
    "df_mean = df_mean.apply(update_exp_group_names, axis=1)\n",
    "df_ensemble = df_ensemble.apply(update_exp_group_names, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter based on threshold strategy and data split - can create more dataframes here, as required\n",
    "df_max_best = df_max[(df_max['threshold_strategy']=='best') & (df_max['split'] == DATA_SPLIT)]\n",
    "df_min_default = df_min[(df_min['threshold_strategy']=='default') & (df_min['split'] == DATA_SPLIT)]\n",
    "df_med_default = df_med[(df_med['threshold_strategy']=='default') & (df_med['split'] == DATA_SPLIT)]\n",
    "df_mean_default = df_mean[(df_mean['threshold_strategy']=='default') & (df_mean['split'] == DATA_SPLIT)]\n",
    "df_ensemble_best = df_ensemble[(df_ensemble['threshold_strategy']=='best') & (df_ensemble['split'] == DATA_SPLIT)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot the results for the metrics (values) to be shown in the table\n",
    "df_max_best = pd.pivot_table(df_max_best, index='exp_group', columns='language_pair', values=VALUES)\n",
    "df_max_best = df_max_best.rename_axis(None, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_min_default = pd.pivot_table(df_min_default, index='exp_group', columns='language_pair', values=VALUES)\n",
    "df_min_default = df_min_default.rename_axis(None, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_med_default = pd.pivot_table(df_med_default, index='exp_group', columns='language_pair', values=VALUES)\n",
    "df_med_default = df_med_default.rename_axis(None, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mean_default = pd.pivot_table(df_mean_default, index='exp_group', columns='language_pair', values=VALUES)\n",
    "df_mean_default = df_mean_default.rename_axis(None, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ensemble_best = pd.pivot_table(df_ensemble_best, index='exp_group', columns='language_pair', values=VALUES)\n",
    "df_ensemble_best = df_ensemble_best.rename_axis(None, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create table for columns and content \n",
    "# NOTE: Should make this a function and pass the dataframe through as a parameter\n",
    "if len(VALUES) == 1:\n",
    "    col_names = ['experiment_group', 'en-cs', 'en-de', 'en-ja', 'en-zh']\n",
    "    di_med_default = {df_med_default.index[i]: [df_med_default.iloc[i,0], df_med_default.iloc[i,1], df_med_default.iloc[i,2], df_med_default.iloc[i,3]] for i in range(len(df_med_default))}\n",
    "    di_mean_default = {df_mean_default.index[i]: [df_mean_default.iloc[i,0], df_mean_default.iloc[i,1], df_mean_default.iloc[i,2], df_mean_default.iloc[i,3]] for i in range(len(df_mean_default))}\n",
    "    li_med_default = create_latex_table(col_names, di_med_default)\n",
    "    li_mean_default = create_latex_table(col_names, di_mean_default)\n",
    "elif len(VALUES) == 2: # Assume it's precision & recall\n",
    "    col_names = ['experiment_group', 'en-cs', '', 'en-de', '', 'en-ja', '', 'en-zh', '']\n",
    "    di_med_default = {df_med_default.index[i]: [df_med_default.iloc[i,0], df_med_default.iloc[i,4], df_med_default.iloc[i,1], df_med_default.iloc[i,5], df_med_default.iloc[i,2], df_med_default.iloc[i,6], df_med_default.iloc[i,3], df_med_default.iloc[i,7]] for i in range(len(df_med_default))}\n",
    "    li_med_default = create_latex_table(col_names, di_med_default)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{table}\n",
      "\\centering\n",
      "\\begin{tabular}{c|ccccccccc}\n",
      " & EXPERIMENT_GROUP & EN-CS &  & EN-DE &  & EN-JA &  & EN-ZH & \\\\\n",
      "\\hline\n",
      "baseline & 0.581 & 0.228 & 0.696 & 0.247 & 0.267 & 0.049 & 0.500 & 0.038 \\\\\n",
      "prompt_GEMBA & 0.503 & 0.503 & 0.577 & 0.427 & 0.155 & 0.646 & 0.326 & 0.639 \\\\\n",
      "prompt_basic & 0.497 & 0.519 & 0.655 & 0.389 & 0.222 & 0.488 & 0.394 & 0.506 \\\\\n",
      "second_step_base_auth_data & 0.590 & 0.587 & 0.744 & 0.465 & 0.264 & 0.171 & 0.397 & 0.437 \\\\\n",
      "second_step_base_demetr_auth_data & 0.537 & 0.614 & 0.682 & 0.625 & 0.252 & 0.415 & 0.398 & 0.297 \\\\\n",
      "second_step_base_demetr_data & 0.593 & 0.593 & 0.690 & 0.549 & 0.271 & 0.439 & 0.378 & 0.373 \\\\\n",
      "second_step_base_wmt22_data & nan & nan & 0.633 & 0.562 & nan & nan & nan & nan \\\\\n",
      "second_step_base_wmt22_small_data & nan & nan & 0.739 & 0.472 & nan & nan & nan & nan \\\\\n",
      "train_monolingual_auth_data & 0.527 & 0.614 & 0.706 & 0.517 & 0.250 & 0.232 & 0.463 & 0.316 \\\\\n",
      "train_monolingual_auth_data_calibrated & 0.682 & 0.307 & 0.677 & 0.517 & 0.167 & 0.024 & 0.566 & 0.190 \\\\\n",
      "train_multilingual_auth_data_all & 0.575 & 0.566 & 0.664 & 0.590 & 0.283 & 0.390 & 0.408 & 0.462 \\\\\n",
      "train_multilingual_auth_data_single & 0.552 & 0.614 & 0.628 & 0.691 & 0.253 & 0.305 & 0.404 & 0.468 \\\\\n",
      "train_multilingual_auth_demetr_data_single & 0.567 & 0.450 & 0.682 & 0.500 & 0.284 & 0.232 & 0.377 & 0.361 \\\\\n",
      "train_multilingual_auth_wmt22_data_single & nan & nan & 0.740 & 0.434 & nan & nan & nan & nan \\\\\n",
      "wmt21_annotator & 0.438 & 0.709 & 0.591 & 0.688 & 0.147 & 0.683 & 0.305 & 0.671 \\\\\n",
      "\\hline\n",
      "\\end{tabular}\n",
      "\\end{table}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print whichever data are of interest\n",
    "print(li_med_default)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtqe-Yrqycps9-py3.9",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
