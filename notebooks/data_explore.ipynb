{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path to the ARC-MTQE directory\n",
    "main_dir = os.path.dirname(os.getcwd())\n",
    "data_dir = os.path.join(main_dir, \"data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_data_stats(n_rows, n_segments, n_critical_errors):\n",
    "    \"\"\"\n",
    "    Print data summary statistics.\n",
    "    \"\"\"\n",
    "    print(f\"Number of rows: {n_rows}\")\n",
    "    print(f\"Number of segments: {n_segments}\")\n",
    "    print(f\"Number of critical errors: {n_critical_errors}\")\n",
    "    print(f\"Percentage critical errors: {n_critical_errors/n_segments}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WMT 2021 critical errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contains train, dev and test data\n",
    "mlqe_pe_data_dir = os.path.join(data_dir, \"mlqe-pe\", \"data\")\n",
    "\n",
    "language_pairs = [\"encs\", \"ende\", \"enja\", \"enzh\"]\n",
    "\n",
    "for lp in language_pairs:\n",
    "    n_rows = 0\n",
    "    n_segments = 0\n",
    "    n_critical_errors = 0\n",
    "\n",
    "    path_dev = os.path.join(mlqe_pe_data_dir, \"catastrophic_errors\", f\"{lp}_majority_dev.tsv\")\n",
    "    path_train = os.path.join(mlqe_pe_data_dir, \"catastrophic_errors\", f\"{lp}_majority_train.tsv\")\n",
    "    path_test = os.path.join(mlqe_pe_data_dir, \"catastrophic_errors\", f\"{lp}_majority_test_blind.tsv\")\n",
    "    path_goldlabels = os.path.join(mlqe_pe_data_dir, \"catastrophic_errors_goldlabels\", f\"{lp}_majority_test_goldlabels\", \"goldlabels.txt\")\n",
    "\n",
    "    df_dev = pd.read_csv(path_dev, sep=\"\\t\", header=None, names=[\"idx\", \"source\", \"target\", \"annotations\", \"label\"])\n",
    "    df_train = pd.read_csv(path_train, sep=\"\\t\", header=None, names=[\"idx\", \"source\", \"target\", \"annotations\", \"label\"])\n",
    "    df_test = pd.read_csv(path_test, sep=\"\\t\", header=None, names=[\"idx\", \"source\", \"target\"])\n",
    "    df_labels = pd.read_csv( path_goldlabels, sep=\"\\t\", header=None, names=[\"lang_pair\", \"ref\", \"idx\", \"label\"])\n",
    "    df_test_labelled = pd.merge(df_test, df_labels, on='idx')\n",
    "\n",
    "    for df in [df_train, df_dev, df_test_labelled]:\n",
    "        n_rows += df.shape[0]\n",
    "        n_segments += df[\"idx\"].nunique()\n",
    "        n_critical_errors += df[df[\"label\"] == \"ERR\"].shape[0]\n",
    "\n",
    "    print(lp)\n",
    "    print_data_stats(n_rows, n_segments, n_critical_errors)\n",
    "    print(\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## WMT 2022 critical errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wmt_data_dir = os.path.join(data_dir, \"wmt-qe-2022-data\")\n",
    "\n",
    "language_pairs = [\"en-de\", \"pt-en\"]\n",
    "for lp in language_pairs:\n",
    "    n_rows = 0\n",
    "    n_segments = 0\n",
    "    n_critical_errors = 0\n",
    "\n",
    "    path_train = os.path.join(wmt_data_dir, \"train-dev_data\", \"task3_ced\", \"train\", lp, f\"{lp}-train\", \"train.label\")\n",
    "    path_dev = os.path.join(wmt_data_dir, \"train-dev_data\", \"task3_ced\", \"dev\", lp, f\"{lp}-dev\", \"dev.label\")\n",
    "    path_test = os.path.join(wmt_data_dir, \"test_data-gold_labels\", \"task3_ced\", lp, f\"test.2022.{lp}.label\")\n",
    "\n",
    "    df_train_labels = pd.read_csv(path_train, names=[\"label\"])\n",
    "    df_dev_labels = pd.read_csv(path_dev, names=[\"label\"])\n",
    "    df_test_labels = pd.read_csv(path_test, names=[\"label\"])\n",
    "\n",
    "    for df in [df_train_labels, df_dev_labels, df_test_labels]:\n",
    "        n = df.shape[0]\n",
    "        n_bad = df[df[\"label\"]==\"BAD\"].shape[0]\n",
    "\n",
    "        n_rows += n\n",
    "        n_segments += n\n",
    "        n_critical_errors += n_bad\n",
    "\n",
    "    print(lp)\n",
    "    print_data_stats(n_rows, n_segments, n_critical_errors)\n",
    "    print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DEMETR\n",
    "\n",
    "The below numbers do not correspond to the paper which lists 10 critical error categories. However, the dataset has 12 critical error categories + one of the baselines is listed as a critical error as well. This brings the total to 13."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "demetr_data_dir = os.path.join(data_dir, \"demetr\", \"dataset\")\n",
    "dfs = []\n",
    "for filename in os.listdir(demetr_data_dir):\n",
    "    f = os.path.join(demetr_data_dir, filename)\n",
    "    df = pd.read_json(f)\n",
    "    dfs.append(df)\n",
    "\n",
    "demetr_df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Number of segments per language pair: \", demetr_df.groupby('lang_tag')['id'].count().unique())\n",
    "print(\"Number of unique segments per language pair: \", demetr_df.groupby('lang_tag')['id'].nunique().unique())\n",
    "print(\"Number of error IDs per language pair: \", demetr_df.groupby('lang_tag')['pert_id'].nunique().unique())\n",
    "print(\"Number of error names per language pair: \", demetr_df.groupby('lang_tag')['pert_name'].nunique().unique())\n",
    "print(\"Number of language pairs per error category: \", demetr_df.groupby('pert_name')['lang_tag'].nunique().unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below cells show that `pert_id` values 5 and 6 are missing. Looking at the corresponding files `major_id5_pp_removed` and `critical_id6_addition.json`, the listed `pert_id` within the files is 8 instead of the expected 5 and 6. However, it seems that the `pert_name` column is used correctly in all files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "set(np.arange(1, 36, 1)) - set(demetr_df['pert_id'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = n_segments = demetr_df.shape[0]\n",
    "# n_critical_errors = demetr_df[demetr_df['severity'] == 'critical'].shape[0]\n",
    "\n",
    "# note: in the paper, there are 10 critical error categories --> 10,000 segments \n",
    "n_critical_errors = 10000\n",
    "\n",
    "print_data_stats(n_rows, n_segments, n_critical_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Unbabel MQM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = os.path.join(data_dir, \"unbabel\", \"mqm_generalMT2022_enru.tsv\")\n",
    "\n",
    "df = pd.read_csv(file_path, sep=\"\\t\", index_col=False)\n",
    "df[['seg_id', 'category', 'severity']].tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['crit_error'] = np.where(df[\"severity\"] == \"critical\", 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rows = df.shape[0]\n",
    "n_segments = df['seg_id'].nunique()\n",
    "n_critical_errors = sum(df.groupby('seg_id')['crit_error'].sum() >= 1)\n",
    "\n",
    "print_data_stats(n_rows, n_segments, n_critical_errors)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mtqe-py3.9",
   "language": "python",
   "name": "mtqe-py3.9"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
